{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "import os\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import ElasticNet as en\n",
    "from sklearn.kernel_ridge import KernelRidge as kr\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold,GroupKFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"d:/tianchi/happiness/happiness_train_complete.csv\", parse_dates=['survey_time'], encoding='latin-1') \n",
    "test = pd.read_csv(\"d:/tianchi/happiness/happiness_test_complete.csv\", parse_dates=['survey_time'], encoding='latin-1')\n",
    "train = train[train[\"happiness\"]!=-8].reset_index(drop=True)\n",
    "train_data_copy = train.copy()\n",
    "target_col = \"happiness\"\n",
    "target = train_data_copy[target_col]\n",
    "del train_data_copy[target_col]\n",
    "\n",
    "data = pd.concat([train_data_copy,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7988.000000\n",
       "mean        3.867927\n",
       "std         0.818717\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.happiness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make feature 139 +5 = 144\n",
    "def getres1(row):\n",
    "    return len([x for x in row.values if type(x)==int and x<0])\n",
    "\n",
    "def getres2(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-8])\n",
    "\n",
    "def getres3(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-1])\n",
    "\n",
    "def getres4(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-2])\n",
    "\n",
    "def getres5(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-3])\n",
    "\n",
    "#调查问卷有效程度\n",
    "data['neg1'] = data[data.columns].apply(lambda row:getres1(row),axis=1)\n",
    "data.loc[data['neg1']>20,'neg1'] = 20  #平滑处理\n",
    "\n",
    "data['neg2'] = data[data.columns].apply(lambda row:getres2(row),axis=1)\n",
    "data['neg3'] = data[data.columns].apply(lambda row:getres3(row),axis=1)\n",
    "data['neg4'] = data[data.columns].apply(lambda row:getres4(row),axis=1)\n",
    "data['neg5'] = data[data.columns].apply(lambda row:getres5(row),axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填充缺失值 共25列 去掉4列 填充21列\n",
    "\n",
    "data['work_status'] = data['work_status'].fillna(0)\n",
    "data['work_yr'] = data['work_yr'].fillna(0)\n",
    "data['work_manage'] = data['work_manage'].fillna(0)\n",
    "data['work_type'] = data['work_type'].fillna(0)\n",
    "\n",
    "data['edu_yr'] = data['edu_yr'].fillna(0)\n",
    "data['edu_status'] = data['edu_status'].fillna(0)\n",
    "\n",
    "data['s_work_type'] = data['s_work_type'].fillna(0)\n",
    "data['s_work_status'] = data['s_work_status'].fillna(0)\n",
    "data['s_political'] = data['s_political'].fillna(0)\n",
    "data['s_hukou'] = data['s_hukou'].fillna(0)\n",
    "data['s_income'] = data['s_income'].fillna(0)\n",
    "data['s_birth'] = data['s_birth'].fillna(0)\n",
    "data['s_edu'] = data['s_edu'].fillna(0)\n",
    "data['s_work_exper'] = data['s_work_exper'].fillna(0)\n",
    "\n",
    "data['minor_child'] = data['minor_child'].fillna(0)\n",
    "data['marital_now'] = data['marital_now'].fillna(0)\n",
    "data['marital_1st'] = data['marital_1st'].fillna(0)\n",
    "data['social_neighbor']=data['social_neighbor'].fillna(0)\n",
    "data['social_friend']=data['social_friend'].fillna(0)\n",
    "data['hukou_loc']=data['hukou_loc'].fillna(1)\n",
    "data['family_income']=data['family_income'].fillna(66365)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10956, 272)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_type</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>depression/age</th>\n",
       "      <th>floor_area/age</th>\n",
       "      <th>health/age</th>\n",
       "      <th>class_10_diff/age</th>\n",
       "      <th>class/age</th>\n",
       "      <th>health_problem/age</th>\n",
       "      <th>family_status/age</th>\n",
       "      <th>leisure_sum/age</th>\n",
       "      <th>public_service_sum/age</th>\n",
       "      <th>trust_sum/age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>0.666638</td>\n",
       "      <td>0.925941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>1.344444</td>\n",
       "      <td>0.891344</td>\n",
       "      <td>1.359551</td>\n",
       "      <td>1.011792</td>\n",
       "      <td>1.130778</td>\n",
       "      <td>1.188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343537</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>1.150485</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>1.195762</td>\n",
       "      <td>1.055679</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>1.193204</td>\n",
       "      <td>0.803693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>0.642329</td>\n",
       "      <td>1.276353</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>1.199143</td>\n",
       "      <td>1.188329</td>\n",
       "      <td>1.162630</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>1.153810</td>\n",
       "      <td>1.300950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>1.116803</td>\n",
       "      <td>1.093645</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>1.117428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_type  province  city  county  survey_time  gender  birth  \\\n",
       "0   1            1        12    32      59         1970       1   1959   \n",
       "1   2            2        18    52      85         1970       1   1992   \n",
       "2   3            2        29    83     126         1970       2   1967   \n",
       "3   4            2        10    28      51         1970       2   1943   \n",
       "4   5            1         7    18      36         1970       2   1994   \n",
       "\n",
       "   nationality  religion  ...  depression/age  floor_area/age health/age  \\\n",
       "0            1         1  ...        1.285211        0.410351   0.848837   \n",
       "1            1         1  ...        0.733333        0.952824   1.179337   \n",
       "2            1         0  ...        1.343537        0.972328   1.150485   \n",
       "3            1         1  ...        1.111663        0.642329   1.276353   \n",
       "4            1         1  ...        0.750000        0.587284   1.177106   \n",
       "\n",
       "   class_10_diff/age  class/age  health_problem/age  family_status/age  \\\n",
       "0           0.000000   0.683307            0.521429           0.733668   \n",
       "1           1.012552   1.344444            0.891344           1.359551   \n",
       "2           1.190955   1.195762            1.055679           1.190955   \n",
       "3           4.977778   1.199143            1.188329           1.162630   \n",
       "4           0.000000   0.236957            1.116803           1.093645   \n",
       "\n",
       "   leisure_sum/age  public_service_sum/age  trust_sum/age  \n",
       "0         0.724620                0.666638       0.925941  \n",
       "1         1.011792                1.130778       1.188442  \n",
       "2         0.966470                1.193204       0.803693  \n",
       "3         0.899346                1.153810       1.300950  \n",
       "4         1.045313                0.728161       1.117428  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#144+1 =145\n",
    "data['survey_time'] = pd.to_datetime(data['survey_time'], format='%Y-%m-%d',errors='coerce')\n",
    "data['survey_time'] = data['survey_time'].dt.year\n",
    "data['age'] = data['survey_time']-data['birth']\n",
    "#年龄分箱 145+1=146\n",
    "bins = [0,17,26,34,50,63,100]\n",
    "data['age_bin'] = pd.cut(data['age'], bins, labels=[0,1,2,3,4,5])\n",
    "#对‘宗教’处理\n",
    "data.loc[data['religion']<0,'religion'] = 1\n",
    "data.loc[data['religion_freq']<0,'religion_freq'] = 1\n",
    "#对‘教育程度’处理\n",
    "data.loc[data['edu']<0,'edu'] = 4\n",
    "data.loc[data['edu_status']<0,'edu_status'] = 0\n",
    "data.loc[data['edu_yr']<0,'edu_yr'] = 0\n",
    "#对‘个人收入’处理\n",
    "data.loc[data['income']<0,'income'] = 0\n",
    "#对‘政治面貌’处理\n",
    "data.loc[data['political']<0,'political'] = 1\n",
    "#对体重处理\n",
    "data.loc[(data['weight_jin']<=80)&(data['height_cm']>=160),'weight_jin']= data['weight_jin']*2\n",
    "data.loc[data['weight_jin']<=60,'weight_jin']= data['weight_jin']*2\n",
    "#对身高处理\n",
    "data.loc[data['height_cm']<150,'height_cm'] = 150\n",
    "#对‘健康’处理\n",
    "data.loc[data['health']<0,'health'] = 4\n",
    "data.loc[data['health_problem']<0,'health_problem'] = 4\n",
    "#对‘沮丧’处理\n",
    "data.loc[data['depression']<0,'depression'] = 4\n",
    "#对‘媒体’处理\n",
    "data.loc[data['media_1']<0,'media_1'] = 1\n",
    "data.loc[data['media_2']<0,'media_2'] = 1\n",
    "data.loc[data['media_3']<0,'media_3'] = 1\n",
    "data.loc[data['media_4']<0,'media_4'] = 1\n",
    "data.loc[data['media_5']<0,'media_5'] = 1\n",
    "data.loc[data['media_6']<0,'media_6'] = 1\n",
    "#对‘空闲活动’处理\n",
    "data.loc[data['leisure_1']<0,'leisure_1'] = 1\n",
    "data.loc[data['leisure_2']<0,'leisure_2'] = 5\n",
    "data.loc[data['leisure_3']<0,'leisure_3'] = 3\n",
    "data.loc[data['leisure_4']<0,'leisure_4'] = data['leisure_4'].mode()\n",
    "data.loc[data['leisure_5']<0,'leisure_5'] = data['leisure_5'].mode()\n",
    "data.loc[data['leisure_6']<0,'leisure_6'] = data['leisure_6'].mode()\n",
    "data.loc[data['leisure_7']<0,'leisure_7'] = data['leisure_7'].mode()\n",
    "data.loc[data['leisure_8']<0,'leisure_8'] = data['leisure_8'].mode()\n",
    "data.loc[data['leisure_9']<0,'leisure_9'] = data['leisure_9'].mode()\n",
    "data.loc[data['leisure_10']<0,'leisure_10'] = data['leisure_10'].mode()\n",
    "data.loc[data['leisure_11']<0,'leisure_11'] = data['leisure_11'].mode()\n",
    "data.loc[data['leisure_12']<0,'leisure_12'] = data['leisure_12'].mode()\n",
    "data.loc[data['socialize']<0,'socialize'] = 2\n",
    "data.loc[data['relax']<0,'relax'] = 4\n",
    "data.loc[data['learn']<0,'learn'] = 1\n",
    "#对‘社交’处理\n",
    "data.loc[data['social_neighbor']<0,'social_neighbor'] = 0\n",
    "data.loc[data['social_friend']<0,'social_friend'] = 0\n",
    "data.loc[data['socia_outing']<0,'socia_outing'] = 1\n",
    "data.loc[data['neighbor_familiarity']<0,'social_neighbor']= 4\n",
    "#对‘社会公平性’处理\n",
    "data.loc[data['equity']<0,'equity'] = 4\n",
    "#对‘社会等级’处理\n",
    "data.loc[data['class_10_before']<0,'class_10_before'] = 3\n",
    "data.loc[data['class']<0,'class'] = 5\n",
    "data.loc[data['class_10_after']<0,'class_10_after'] = 5\n",
    "data.loc[data['class_14']<0,'class_14'] = 2\n",
    "#对‘工作情况’处理\n",
    "data.loc[data['work_status']<0,'work_status'] = 0\n",
    "data.loc[data['work_yr']<0,'work_yr'] = 0\n",
    "data.loc[data['work_manage']<0,'work_manage'] = 0\n",
    "data.loc[data['work_type']<0,'work_type'] = 0\n",
    "#对‘社会保障’处理\n",
    "data.loc[data['insur_1']<0,'insur_1'] = 1\n",
    "data.loc[data['insur_2']<0,'insur_2'] = 1\n",
    "data.loc[data['insur_3']<0,'insur_3'] = 1\n",
    "data.loc[data['insur_4']<0,'insur_4'] = 1\n",
    "data.loc[data['insur_1']==0,'insur_1'] = 0\n",
    "data.loc[data['insur_2']==0,'insur_2'] = 0\n",
    "data.loc[data['insur_3']==0,'insur_3'] = 0\n",
    "data.loc[data['insur_4']==0,'insur_4'] = 0\n",
    "\n",
    "#对家庭情况处理\n",
    "family_income_mean = data['family_income'].mean()\n",
    "data.loc[data['family_income']<0,'family_income'] = family_income_mean\n",
    "data.loc[data['family_m']<0,'family_m'] = 2\n",
    "data.loc[data['family_status']<0,'family_status'] = 3\n",
    "data.loc[data['house']<0,'house'] = 1\n",
    "data.loc[data['car']<0,'car'] = 0\n",
    "data.loc[data['car']==2,'car'] = 0\n",
    "data.loc[data['son']<0,'son'] = 1\n",
    "data.loc[data['daughter']<0,'daughter'] = 0\n",
    "data.loc[data['minor_child']<0,'minor_child'] = 0\n",
    "#对‘婚姻’处理\n",
    "data.loc[data['marital_1st']<0,'marital_1st'] = 0\n",
    "data.loc[data['marital_now']<0,'marital_now'] = 0\n",
    "#对‘配偶’处理\n",
    "data.loc[data['s_birth']<0,'s_birth'] = 0\n",
    "data.loc[data['s_edu']<0,'s_edu'] = 0\n",
    "data.loc[data['s_political']<0,'s_political'] = 0\n",
    "data.loc[data['s_hukou']<0,'s_hukou'] = 0\n",
    "data.loc[data['s_income']<0,'s_income'] = 0\n",
    "data.loc[data['s_work_type']<0,'s_work_type'] = 0\n",
    "data.loc[data['s_work_status']<0,'s_work_status'] = 0\n",
    "data.loc[data['s_work_exper']<0,'s_work_exper'] = 0\n",
    "#对‘父母情况’处理\n",
    "data.loc[data['f_birth']<0,'f_birth'] = 1945\n",
    "data.loc[data['f_edu']<0,'f_edu'] = 1\n",
    "data.loc[data['f_political']<0,'f_political'] = 1\n",
    "data.loc[data['f_work_14']<0,'f_work_14'] = 2\n",
    "data.loc[data['m_birth']<0,'m_birth'] = 1940\n",
    "data.loc[data['m_edu']<0,'m_edu'] = 1\n",
    "data.loc[data['m_political']<0,'m_political'] = 1\n",
    "data.loc[data['m_work_14']<0,'m_work_14'] = 2\n",
    "#和同龄人相比社会经济地位\n",
    "data.loc[data['status_peer']<0,'status_peer'] = 2\n",
    "#和3年前比社会经济地位\n",
    "data.loc[data['status_3_before']<0,'status_3_before'] = 2\n",
    "#对‘观点’处理\n",
    "data.loc[data['view']<0,'view'] = 4\n",
    "#对期望年收入处理\n",
    "data.loc[data['inc_ability']<=0,'inc_ability']= 2\n",
    "inc_exp_mean = data['inc_exp'].mean()\n",
    "data.loc[data['inc_exp']<=0,'inc_exp']= inc_exp_mean\n",
    "\n",
    "#部分特征处理\n",
    "for i in range(1,9+1):\n",
    "    data.loc[data['public_service_'+str(i)]<0,'public_service_'+str(i)] = data['public_service_'+str(i)].dropna().mode().values\n",
    "for i in range(1,13+1):\n",
    "    data.loc[data['trust_'+str(i)]<0,'trust_'+str(i)] = data['trust_'+str(i)].dropna().mode().values\n",
    "\n",
    "#第一次结婚年龄 147\n",
    "data['marital_1stbir'] = data['marital_1st'] - data['birth'] \n",
    "#最近结婚年龄 148\n",
    "data['marital_nowtbir'] = data['marital_now'] - data['birth'] \n",
    "#是否再婚 149\n",
    "data['mar'] = data['marital_nowtbir'] - data['marital_1stbir']\n",
    "#配偶年龄 150\n",
    "data['marital_sbir'] = data['marital_now']-data['s_birth']\n",
    "#配偶年龄差 151\n",
    "data['age_'] = data['marital_nowtbir'] - data['marital_sbir'] \n",
    "\n",
    "#收入比 151+7 =158\n",
    "data['income/s_income'] = data['income']/(data['s_income']+1)\n",
    "data['income+s_income'] = data['income']+(data['s_income']+1)\n",
    "data['income/family_income'] = data['income']/(data['family_income']+1)\n",
    "data['all_income/family_income'] = (data['income']+data['s_income'])/(data['family_income']+1)\n",
    "data['income/inc_exp'] = data['income']/(data['inc_exp']+1)\n",
    "data['family_income/m'] = data['family_income']/(data['family_m']+0.01)\n",
    "data['income/m'] = data['income']/(data['family_m']+0.01)\n",
    "\n",
    "#收入/面积比 158+4=162\n",
    "data['income/floor_area'] = data['income']/(data['floor_area']+0.01)\n",
    "data['all_income/floor_area'] = (data['income']+data['s_income'])/(data['floor_area']+0.01)\n",
    "data['family_income/floor_area'] = data['family_income']/(data['floor_area']+0.01)\n",
    "data['floor_area/m'] = data['floor_area']/(data['family_m']+0.01)\n",
    "\n",
    "#class 162+3=165\n",
    "data['class_10_diff'] = (data['class_10_after'] - data['class'])\n",
    "data['class_diff'] = data['class'] - data['class_10_before']\n",
    "data['class_14_diff'] = data['class'] - data['class_14']\n",
    "#悠闲指数 166\n",
    "leisure_fea_lis = ['leisure_'+str(i) for i in range(1,13)]\n",
    "data['leisure_sum'] = data[leisure_fea_lis].sum(axis=1) #skew\n",
    "#满意指数 167\n",
    "public_service_fea_lis = ['public_service_'+str(i) for i in range(1,10)]\n",
    "data['public_service_sum'] = data[public_service_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#信任指数 168\n",
    "trust_fea_lis = ['trust_'+str(i) for i in range(1,14)]\n",
    "data['trust_sum'] = data[trust_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#province mean 168+13=181\n",
    "data['province_income_mean'] = data.groupby(['province'])['income'].transform('mean').values\n",
    "data['province_family_income_mean'] = data.groupby(['province'])['family_income'].transform('mean').values\n",
    "data['province_equity_mean'] = data.groupby(['province'])['equity'].transform('mean').values\n",
    "data['province_depression_mean'] = data.groupby(['province'])['depression'].transform('mean').values\n",
    "data['province_floor_area_mean'] = data.groupby(['province'])['floor_area'].transform('mean').values\n",
    "data['province_health_mean'] = data.groupby(['province'])['health'].transform('mean').values\n",
    "data['province_class_10_diff_mean'] = data.groupby(['province'])['class_10_diff'].transform('mean').values\n",
    "data['province_class_mean'] = data.groupby(['province'])['class'].transform('mean').values\n",
    "data['province_health_problem_mean'] = data.groupby(['province'])['health_problem'].transform('mean').values\n",
    "data['province_family_status_mean'] = data.groupby(['province'])['family_status'].transform('mean').values\n",
    "data['province_leisure_sum_mean'] = data.groupby(['province'])['leisure_sum'].transform('mean').values\n",
    "data['province_public_service_sum_mean'] = data.groupby(['province'])['public_service_sum'].transform('mean').values\n",
    "data['province_trust_sum_mean'] = data.groupby(['province'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#city   mean 181+13=194\n",
    "data['city_income_mean'] = data.groupby(['city'])['income'].transform('mean').values\n",
    "data['city_family_income_mean'] = data.groupby(['city'])['family_income'].transform('mean').values\n",
    "data['city_equity_mean'] = data.groupby(['city'])['equity'].transform('mean').values\n",
    "data['city_depression_mean'] = data.groupby(['city'])['depression'].transform('mean').values\n",
    "data['city_floor_area_mean'] = data.groupby(['city'])['floor_area'].transform('mean').values\n",
    "data['city_health_mean'] = data.groupby(['city'])['health'].transform('mean').values\n",
    "data['city_class_10_diff_mean'] = data.groupby(['city'])['class_10_diff'].transform('mean').values\n",
    "data['city_class_mean'] = data.groupby(['city'])['class'].transform('mean').values\n",
    "data['city_health_problem_mean'] = data.groupby(['city'])['health_problem'].transform('mean').values\n",
    "data['city_family_status_mean'] = data.groupby(['city'])['family_status'].transform('mean').values\n",
    "data['city_leisure_sum_mean'] = data.groupby(['city'])['leisure_sum'].transform('mean').values\n",
    "data['city_public_service_sum_mean'] = data.groupby(['city'])['public_service_sum'].transform('mean').values\n",
    "data['city_trust_sum_mean'] = data.groupby(['city'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#county  mean 194 + 13 = 207\n",
    "data['county_income_mean'] = data.groupby(['county'])['income'].transform('mean').values\n",
    "data['county_family_income_mean'] = data.groupby(['county'])['family_income'].transform('mean').values\n",
    "data['county_equity_mean'] = data.groupby(['county'])['equity'].transform('mean').values\n",
    "data['county_depression_mean'] = data.groupby(['county'])['depression'].transform('mean').values\n",
    "data['county_floor_area_mean'] = data.groupby(['county'])['floor_area'].transform('mean').values\n",
    "data['county_health_mean'] = data.groupby(['county'])['health'].transform('mean').values\n",
    "data['county_class_10_diff_mean'] = data.groupby(['county'])['class_10_diff'].transform('mean').values\n",
    "data['county_class_mean'] = data.groupby(['county'])['class'].transform('mean').values\n",
    "data['county_health_problem_mean'] = data.groupby(['county'])['health_problem'].transform('mean').values\n",
    "data['county_family_status_mean'] = data.groupby(['county'])['family_status'].transform('mean').values\n",
    "data['county_leisure_sum_mean'] = data.groupby(['county'])['leisure_sum'].transform('mean').values\n",
    "data['county_public_service_sum_mean'] = data.groupby(['county'])['public_service_sum'].transform('mean').values\n",
    "data['county_trust_sum_mean'] = data.groupby(['county'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#ratio 相比同省 207 + 13 =220\n",
    "data['income/province'] = data['income']/(data['province_income_mean'])                                      \n",
    "data['family_income/province'] = data['family_income']/(data['province_family_income_mean'])   \n",
    "data['equity/province'] = data['equity']/(data['province_equity_mean'])       \n",
    "data['depression/province'] = data['depression']/(data['province_depression_mean'])                                                \n",
    "data['floor_area/province'] = data['floor_area']/(data['province_floor_area_mean'])\n",
    "data['health/province'] = data['health']/(data['province_health_mean'])\n",
    "data['class_10_diff/province'] = data['class_10_diff']/(data['province_class_10_diff_mean'])\n",
    "data['class/province'] = data['class']/(data['province_class_mean'])\n",
    "data['health_problem/province'] = data['health_problem']/(data['province_health_problem_mean'])\n",
    "data['family_status/province'] = data['family_status']/(data['province_family_status_mean'])\n",
    "data['leisure_sum/province'] = data['leisure_sum']/(data['province_leisure_sum_mean'])\n",
    "data['public_service_sum/province'] = data['public_service_sum']/(data['province_public_service_sum_mean'])\n",
    "data['trust_sum/province'] = data['trust_sum']/(data['province_trust_sum_mean']+1)\n",
    "\n",
    "#ratio 相比同市 220 + 13 =233\n",
    "data['income/city'] = data['income']/(data['city_income_mean'])                                      \n",
    "data['family_income/city'] = data['family_income']/(data['city_family_income_mean'])   \n",
    "data['equity/city'] = data['equity']/(data['city_equity_mean'])       \n",
    "data['depression/city'] = data['depression']/(data['city_depression_mean'])                                                \n",
    "data['floor_area/city'] = data['floor_area']/(data['city_floor_area_mean'])\n",
    "data['health/city'] = data['health']/(data['city_health_mean'])\n",
    "data['class_10_diff/city'] = data['class_10_diff']/(data['city_class_10_diff_mean'])\n",
    "data['class/city'] = data['class']/(data['city_class_mean'])\n",
    "data['health_problem/city'] = data['health_problem']/(data['city_health_problem_mean'])\n",
    "data['family_status/city'] = data['family_status']/(data['city_family_status_mean'])\n",
    "data['leisure_sum/city'] = data['leisure_sum']/(data['city_leisure_sum_mean'])\n",
    "data['public_service_sum/city'] = data['public_service_sum']/(data['city_public_service_sum_mean'])\n",
    "data['trust_sum/city'] = data['trust_sum']/(data['city_trust_sum_mean'])\n",
    "\n",
    "#ratio 相比同个地区 233 + 13 =246\n",
    "data['income/county'] = data['income']/(data['county_income_mean'])                                      \n",
    "data['family_income/county'] = data['family_income']/(data['county_family_income_mean'])   \n",
    "data['equity/county'] = data['equity']/(data['county_equity_mean'])       \n",
    "data['depression/county'] = data['depression']/(data['county_depression_mean'])                                                \n",
    "data['floor_area/county'] = data['floor_area']/(data['county_floor_area_mean'])\n",
    "data['health/county'] = data['health']/(data['county_health_mean'])\n",
    "data['class_10_diff/county'] = data['class_10_diff']/(data['county_class_10_diff_mean'])\n",
    "data['class/county'] = data['class']/(data['county_class_mean'])\n",
    "data['health_problem/county'] = data['health_problem']/(data['county_health_problem_mean'])\n",
    "data['family_status/county'] = data['family_status']/(data['county_family_status_mean'])\n",
    "data['leisure_sum/county'] = data['leisure_sum']/(data['county_leisure_sum_mean'])\n",
    "data['public_service_sum/county'] = data['public_service_sum']/(data['county_public_service_sum_mean'])\n",
    "data['trust_sum/county'] = data['trust_sum']/(data['county_trust_sum_mean'])\n",
    "\n",
    "#age   mean 246+ 13 =259\n",
    "data['age_income_mean'] = data.groupby(['age'])['income'].transform('mean').values\n",
    "data['age_family_income_mean'] = data.groupby(['age'])['family_income'].transform('mean').values\n",
    "data['age_equity_mean'] = data.groupby(['age'])['equity'].transform('mean').values\n",
    "data['age_depression_mean'] = data.groupby(['age'])['depression'].transform('mean').values\n",
    "data['age_floor_area_mean'] = data.groupby(['age'])['floor_area'].transform('mean').values\n",
    "data['age_health_mean'] = data.groupby(['age'])['health'].transform('mean').values\n",
    "data['age_class_10_diff_mean'] = data.groupby(['age'])['class_10_diff'].transform('mean').values\n",
    "data['age_class_mean'] = data.groupby(['age'])['class'].transform('mean').values\n",
    "data['age_health_problem_mean'] = data.groupby(['age'])['health_problem'].transform('mean').values\n",
    "data['age_family_status_mean'] = data.groupby(['age'])['family_status'].transform('mean').values\n",
    "data['age_leisure_sum_mean'] = data.groupby(['age'])['leisure_sum'].transform('mean').values\n",
    "data['age_public_service_sum_mean'] = data.groupby(['age'])['public_service_sum'].transform('mean').values\n",
    "data['age_trust_sum_mean'] = data.groupby(['age'])['trust_sum'].transform('mean').values\n",
    "\n",
    "# 和同龄人相比259 + 13 =272\n",
    "data['income/age'] = data['income']/(data['age_income_mean'])                                      \n",
    "data['family_income/age'] = data['family_income']/(data['age_family_income_mean'])   \n",
    "data['equity/age'] = data['equity']/(data['age_equity_mean'])       \n",
    "data['depression/age'] = data['depression']/(data['age_depression_mean'])                                                \n",
    "data['floor_area/age'] = data['floor_area']/(data['age_floor_area_mean'])\n",
    "data['health/age'] = data['health']/(data['age_health_mean'])\n",
    "data['class_10_diff/age'] = data['class_10_diff']/(data['age_class_10_diff_mean'])\n",
    "data['class/age'] = data['class']/(data['age_class_mean'])\n",
    "data['health_problem/age'] = data['health_problem']/(data['age_health_problem_mean'])\n",
    "data['family_status/age'] = data['family_status']/(data['age_family_status_mean'])\n",
    "data['leisure_sum/age'] = data['leisure_sum']/(data['age_leisure_sum_mean'])\n",
    "data['public_service_sum/age'] = data['public_service_sum']/(data['age_public_service_sum_mean'])\n",
    "data['trust_sum/age'] = data['trust_sum']/(data['age_trust_sum_mean'])\n",
    "\n",
    "\n",
    "print('shape',data.shape)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 263)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#272-9=263\n",
    "del_list=['id','survey_time','edu_other','invest_other','property_other','join_party','province','city','county']\n",
    "use_feature = [clo for clo in data.columns if clo not in del_list]\n",
    "data.fillna(0,inplace=True)\n",
    "train_shape = train.shape[0]\n",
    "features = data[use_feature].columns\n",
    "X_train_263 = data[:train_shape][use_feature].values\n",
    "y_train = target\n",
    "X_test_263 = data[train_shape:][use_feature].values\n",
    "X_train_263.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 49)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_fea_49 = ['equity','depression','health','class','family_status','health_problem','class_10_after',\n",
    "           'equity/province','equity/city','equity/county',\n",
    "           'depression/province','depression/city','depression/county',\n",
    "           'health/province','health/city','health/county',\n",
    "           'class/province','class/city','class/county',\n",
    "           'family_status/province','family_status/city','family_status/county',\n",
    "           'family_income/province','family_income/city','family_income/county',\n",
    "           'floor_area/province','floor_area/city','floor_area/county',\n",
    "           'leisure_sum/province','leisure_sum/city','leisure_sum/county',\n",
    "           'public_service_sum/province','public_service_sum/city','public_service_sum/county',\n",
    "           'trust_sum/province','trust_sum/city','trust_sum/county',\n",
    "           'income/m','public_service_sum','class_diff','status_3_before','age_income_mean','age_floor_area_mean',\n",
    "           'weight_jin','height_cm',\n",
    "           'health/age','depression/age','equity/age','leisure_sum/age'\n",
    "          ]\n",
    "train_shape = train.shape[0]\n",
    "X_train_49 = data[:train_shape][imp_fea_49].values\n",
    "X_test_49 = data[train_shape:][imp_fea_49].values\n",
    "X_train_49.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fea = ['survey_type','gender','nationality','edu_status','political','hukou','hukou_loc','work_exper','work_status','work_type',\n",
    "           'work_manage','marital','s_political','s_hukou','s_work_exper','s_work_status','s_work_type','f_political','f_work_14',\n",
    "           'm_political','m_work_14']\n",
    "noc_fea = [clo for clo in use_feature if clo not in cat_fea]\n",
    "\n",
    "len(noc_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10956, 141)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_data = data[cat_fea].values\n",
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "oh_data=enc.fit_transform(onehot_data).toarray()\n",
    "oh_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 141)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oh = oh_data[:train_shape,:]\n",
    "X_test_oh = oh_data[train_shape:,:]\n",
    "X_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 383)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_383 = np.column_stack([data[:train_shape][noc_fea].values,X_train_oh])\n",
    "X_test_383 = np.column_stack([data[train_shape:][noc_fea].values,X_test_oh])\n",
    "X_train_383.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[500]\ttraining's l2: 0.506716\tvalid_1's l2: 0.509632\n",
      "[1000]\ttraining's l2: 0.459112\tvalid_1's l2: 0.470082\n",
      "[1500]\ttraining's l2: 0.433129\tvalid_1's l2: 0.454055\n",
      "[2000]\ttraining's l2: 0.4152\tvalid_1's l2: 0.445279\n",
      "[2500]\ttraining's l2: 0.401025\tvalid_1's l2: 0.440707\n",
      "[3000]\ttraining's l2: 0.388743\tvalid_1's l2: 0.437664\n",
      "[3500]\ttraining's l2: 0.377994\tvalid_1's l2: 0.43575\n",
      "[4000]\ttraining's l2: 0.368085\tvalid_1's l2: 0.434466\n",
      "[4500]\ttraining's l2: 0.358898\tvalid_1's l2: 0.43354\n",
      "[5000]\ttraining's l2: 0.350405\tvalid_1's l2: 0.432736\n",
      "[5500]\ttraining's l2: 0.342336\tvalid_1's l2: 0.432232\n",
      "[6000]\ttraining's l2: 0.334708\tvalid_1's l2: 0.43205\n",
      "[6500]\ttraining's l2: 0.32737\tvalid_1's l2: 0.431651\n",
      "[7000]\ttraining's l2: 0.320311\tvalid_1's l2: 0.431429\n",
      "[7500]\ttraining's l2: 0.313477\tvalid_1's l2: 0.431256\n",
      "[8000]\ttraining's l2: 0.307032\tvalid_1's l2: 0.430874\n",
      "[8500]\ttraining's l2: 0.300733\tvalid_1's l2: 0.430899\n",
      "[9000]\ttraining's l2: 0.294725\tvalid_1's l2: 0.43107\n",
      "Early stopping, best iteration is:\n",
      "[8480]\ttraining's l2: 0.301008\tvalid_1's l2: 0.430817\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[500]\ttraining's l2: 0.499301\tvalid_1's l2: 0.529577\n",
      "[1000]\ttraining's l2: 0.450891\tvalid_1's l2: 0.496593\n",
      "[1500]\ttraining's l2: 0.424784\tvalid_1's l2: 0.483009\n",
      "[2000]\ttraining's l2: 0.40669\tvalid_1's l2: 0.476867\n",
      "[2500]\ttraining's l2: 0.392642\tvalid_1's l2: 0.473099\n",
      "[3000]\ttraining's l2: 0.380684\tvalid_1's l2: 0.470672\n",
      "[3500]\ttraining's l2: 0.369973\tvalid_1's l2: 0.468957\n",
      "[4000]\ttraining's l2: 0.360324\tvalid_1's l2: 0.467829\n",
      "[4500]\ttraining's l2: 0.351382\tvalid_1's l2: 0.467069\n",
      "[5000]\ttraining's l2: 0.342906\tvalid_1's l2: 0.466767\n",
      "[5500]\ttraining's l2: 0.335129\tvalid_1's l2: 0.466391\n",
      "[6000]\ttraining's l2: 0.327559\tvalid_1's l2: 0.465903\n",
      "[6500]\ttraining's l2: 0.320259\tvalid_1's l2: 0.465802\n",
      "[7000]\ttraining's l2: 0.31348\tvalid_1's l2: 0.465249\n",
      "[7500]\ttraining's l2: 0.307041\tvalid_1's l2: 0.465116\n",
      "[8000]\ttraining's l2: 0.300715\tvalid_1's l2: 0.465269\n",
      "[8500]\ttraining's l2: 0.294645\tvalid_1's l2: 0.464888\n",
      "[9000]\ttraining's l2: 0.288758\tvalid_1's l2: 0.465132\n",
      "Early stopping, best iteration is:\n",
      "[8516]\ttraining's l2: 0.294466\tvalid_1's l2: 0.464853\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[500]\ttraining's l2: 0.500003\tvalid_1's l2: 0.52899\n",
      "[1000]\ttraining's l2: 0.45096\tvalid_1's l2: 0.497247\n",
      "[1500]\ttraining's l2: 0.42438\tvalid_1's l2: 0.484892\n",
      "[2000]\ttraining's l2: 0.406005\tvalid_1's l2: 0.478975\n",
      "[2500]\ttraining's l2: 0.391762\tvalid_1's l2: 0.475908\n",
      "[3000]\ttraining's l2: 0.379633\tvalid_1's l2: 0.474756\n",
      "[3500]\ttraining's l2: 0.368883\tvalid_1's l2: 0.473431\n",
      "[4000]\ttraining's l2: 0.359074\tvalid_1's l2: 0.472363\n",
      "[4500]\ttraining's l2: 0.350119\tvalid_1's l2: 0.472219\n",
      "[5000]\ttraining's l2: 0.34166\tvalid_1's l2: 0.471576\n",
      "[5500]\ttraining's l2: 0.333813\tvalid_1's l2: 0.470883\n",
      "[6000]\ttraining's l2: 0.326201\tvalid_1's l2: 0.470728\n",
      "[6500]\ttraining's l2: 0.319098\tvalid_1's l2: 0.470232\n",
      "[7000]\ttraining's l2: 0.312239\tvalid_1's l2: 0.470151\n",
      "[7500]\ttraining's l2: 0.305745\tvalid_1's l2: 0.470366\n",
      "Early stopping, best iteration is:\n",
      "[6883]\ttraining's l2: 0.313787\tvalid_1's l2: 0.469962\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[500]\ttraining's l2: 0.505021\tvalid_1's l2: 0.50805\n",
      "[1000]\ttraining's l2: 0.45638\tvalid_1's l2: 0.47397\n",
      "[1500]\ttraining's l2: 0.430238\tvalid_1's l2: 0.461815\n",
      "[2000]\ttraining's l2: 0.411988\tvalid_1's l2: 0.455689\n",
      "[2500]\ttraining's l2: 0.397798\tvalid_1's l2: 0.452132\n",
      "[3000]\ttraining's l2: 0.385699\tvalid_1's l2: 0.449704\n",
      "[3500]\ttraining's l2: 0.374818\tvalid_1's l2: 0.447934\n",
      "[4000]\ttraining's l2: 0.364869\tvalid_1's l2: 0.446866\n",
      "[4500]\ttraining's l2: 0.355662\tvalid_1's l2: 0.446082\n",
      "[5000]\ttraining's l2: 0.34722\tvalid_1's l2: 0.445552\n",
      "[5500]\ttraining's l2: 0.339323\tvalid_1's l2: 0.445179\n",
      "[6000]\ttraining's l2: 0.331573\tvalid_1's l2: 0.444962\n",
      "[6500]\ttraining's l2: 0.324203\tvalid_1's l2: 0.444747\n",
      "[7000]\ttraining's l2: 0.317231\tvalid_1's l2: 0.444958\n",
      "[7500]\ttraining's l2: 0.310429\tvalid_1's l2: 0.444693\n",
      "[8000]\ttraining's l2: 0.304128\tvalid_1's l2: 0.444685\n",
      "[8500]\ttraining's l2: 0.297996\tvalid_1's l2: 0.444691\n",
      "Early stopping, best iteration is:\n",
      "[8139]\ttraining's l2: 0.302361\tvalid_1's l2: 0.444512\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[500]\ttraining's l2: 0.504325\tvalid_1's l2: 0.514214\n",
      "[1000]\ttraining's l2: 0.456457\tvalid_1's l2: 0.478309\n",
      "[1500]\ttraining's l2: 0.430925\tvalid_1's l2: 0.4628\n",
      "[2000]\ttraining's l2: 0.412881\tvalid_1's l2: 0.455148\n",
      "[2500]\ttraining's l2: 0.398837\tvalid_1's l2: 0.450586\n",
      "[3000]\ttraining's l2: 0.386967\tvalid_1's l2: 0.447651\n",
      "[3500]\ttraining's l2: 0.376286\tvalid_1's l2: 0.445593\n",
      "[4000]\ttraining's l2: 0.366519\tvalid_1's l2: 0.444442\n",
      "[4500]\ttraining's l2: 0.357391\tvalid_1's l2: 0.443926\n",
      "[5000]\ttraining's l2: 0.348876\tvalid_1's l2: 0.44315\n",
      "[5500]\ttraining's l2: 0.340852\tvalid_1's l2: 0.442899\n",
      "[6000]\ttraining's l2: 0.333274\tvalid_1's l2: 0.442627\n",
      "[6500]\ttraining's l2: 0.326049\tvalid_1's l2: 0.442522\n",
      "[7000]\ttraining's l2: 0.319174\tvalid_1's l2: 0.442792\n",
      "Early stopping, best iteration is:\n",
      "[6511]\ttraining's l2: 0.32589\tvalid_1's l2: 0.442462\n",
      "CV score: 0.45052435\n"
     ]
    }
   ],
   "source": [
    "##### lgb_263\n",
    "lgb_263_param = {\n",
    "'num_leaves': 7,\n",
    "'min_data_in_leaf': 20,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.003,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.18,\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.55,\n",
    "\"bagging_seed\": 14,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l1\": 0.1005,\n",
    "\"lambda_l2\": 0.1996, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)   \n",
    "oof_lgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_lgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_263 = lgb.train(lgb_263_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 800)\n",
    "    oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx], num_iteration=lgb_263.best_iteration)\n",
    "    predictions_lgb_263 += lgb_263.predict(X_test_263, num_iteration=lgb_263.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2016 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------特征重要性\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "df = pd.DataFrame(data[use_feature].columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb_263.feature_importance())\n",
    "df = df.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df.head(50))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:3.40431\tvalid_data-rmse:3.38326\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.406018\tvalid_data-rmse:0.706535\n",
      "[1000]\ttrain-rmse:0.272424\tvalid_data-rmse:0.709464\n",
      "Stopping. Best iteration:\n",
      "[445]\ttrain-rmse:0.423487\tvalid_data-rmse:0.705639\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:3.39808\tvalid_data-rmse:3.40794\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.406888\tvalid_data-rmse:0.689693\n",
      "[1000]\ttrain-rmse:0.273509\tvalid_data-rmse:0.692095\n",
      "Stopping. Best iteration:\n",
      "[523]\ttrain-rmse:0.399233\tvalid_data-rmse:0.689412\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:3.40186\tvalid_data-rmse:3.3931\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.411867\tvalid_data-rmse:0.662618\n",
      "Stopping. Best iteration:\n",
      "[310]\ttrain-rmse:0.48348\tvalid_data-rmse:0.661856\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:3.4024\tvalid_data-rmse:3.39014\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.411925\tvalid_data-rmse:0.664316\n",
      "[1000]\ttrain-rmse:0.275243\tvalid_data-rmse:0.66501\n",
      "Stopping. Best iteration:\n",
      "[617]\ttrain-rmse:0.376437\tvalid_data-rmse:0.663496\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:3.39343\tvalid_data-rmse:3.42628\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.417585\tvalid_data-rmse:0.650288\n",
      "[1000]\ttrain-rmse:0.279321\tvalid_data-rmse:0.651251\n",
      "Stopping. Best iteration:\n",
      "[554]\ttrain-rmse:0.399718\tvalid_data-rmse:0.649753\n",
      "\n",
      "CV score: 0.45474095\n"
     ]
    }
   ],
   "source": [
    "##### xgb_263\n",
    "xgb_263_params = {'eta': 0.02, \n",
    "              'max_depth': 6, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.3, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_xgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_263 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_263_params)\n",
    "    oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]), ntree_limit=xgb_263.best_ntree_limit)\n",
    "    predictions_xgb_263 += xgb_263.predict(xgb.DMatrix(X_test_263), ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   16.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   20.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   20.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.47807088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_rfr_263 = np.zeros(len(X_train_263))\n",
    "predictions_rfr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    rfr_263 = rfr(n_estimators=1600,max_depth=9, min_samples_leaf=9, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.25,verbose=1,n_jobs=-1)\n",
    "    rfr_263.fit(tr_x,tr_y)\n",
    "    oof_rfr_263[val_idx] = rfr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_rfr_263 += rfr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_rfr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6676           0.0067           26.79s\n",
      "         2           0.6435           0.0063           27.22s\n",
      "         3           0.6581           0.0063           25.71s\n",
      "         4           0.6306           0.0062           25.17s\n",
      "         5           0.6414           0.0053           24.93s\n",
      "         6           0.6212           0.0051           25.23s\n",
      "         7           0.6099           0.0056           25.09s\n",
      "         8           0.5999           0.0054           24.73s\n",
      "         9           0.5774           0.0049           24.39s\n",
      "        10           0.6056           0.0045           24.25s\n",
      "        20           0.5247           0.0033           22.92s\n",
      "        30           0.5033           0.0024           22.46s\n",
      "        40           0.4667           0.0016           21.59s\n",
      "        50           0.4262           0.0010           21.10s\n",
      "        60           0.4026           0.0008           20.66s\n",
      "        70           0.4022           0.0006           20.01s\n",
      "        80           0.3734           0.0004           19.30s\n",
      "        90           0.3473           0.0004           18.56s\n",
      "       100           0.3494           0.0001           18.05s\n",
      "       200           0.2717          -0.0000           12.25s\n",
      "       300           0.2319          -0.0001            7.65s\n",
      "       400           0.1972          -0.0001            3.71s\n",
      "       500           0.1718           0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6496           0.0069           21.94s\n",
      "         2           0.6523           0.0064           22.12s\n",
      "         3           0.6595           0.0060           23.13s\n",
      "         4           0.6320           0.0059           23.97s\n",
      "         5           0.6491           0.0055           24.50s\n",
      "         6           0.6077           0.0059           24.23s\n",
      "         7           0.6060           0.0056           24.03s\n",
      "         8           0.6056           0.0051           23.80s\n",
      "         9           0.5992           0.0044           24.42s\n",
      "        10           0.5976           0.0042           24.51s\n",
      "        20           0.5423           0.0036           23.63s\n",
      "        30           0.5043           0.0022           22.58s\n",
      "        40           0.4718           0.0012           21.72s\n",
      "        50           0.4229           0.0011           20.99s\n",
      "        60           0.4054           0.0007           20.24s\n",
      "        70           0.3979           0.0007           19.52s\n",
      "        80           0.3756           0.0003           18.80s\n",
      "        90           0.3590           0.0003           18.21s\n",
      "       100           0.3395           0.0001           17.59s\n",
      "       200           0.2710          -0.0001           12.19s\n",
      "       300           0.2334          -0.0001            7.59s\n",
      "       400           0.1959          -0.0001            3.74s\n",
      "       500           0.1664          -0.0002            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6473           0.0066           21.44s\n",
      "         2           0.6566           0.0076           21.88s\n",
      "         3           0.6475           0.0072           21.84s\n",
      "         4           0.6242           0.0066           21.99s\n",
      "         5           0.6411           0.0057           22.68s\n",
      "         6           0.6306           0.0055           22.68s\n",
      "         7           0.6058           0.0056           22.84s\n",
      "         8           0.5994           0.0057           22.70s\n",
      "         9           0.5969           0.0057           22.75s\n",
      "        10           0.6002           0.0048           22.97s\n",
      "        20           0.5394           0.0034           22.23s\n",
      "        30           0.4832           0.0024           21.74s\n",
      "        40           0.4598           0.0014           21.06s\n",
      "        50           0.4332           0.0010           20.44s\n",
      "        60           0.3988           0.0011           19.71s\n",
      "        70           0.3783           0.0004           19.08s\n",
      "        80           0.3572           0.0005           18.40s\n",
      "        90           0.3558           0.0004           17.79s\n",
      "       100           0.3308           0.0002           17.19s\n",
      "       200           0.2715          -0.0001           12.35s\n",
      "       300           0.2244          -0.0000            7.73s\n",
      "       400           0.1931           0.0000            3.73s\n",
      "       500           0.1696          -0.0001            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6576           0.0071           23.47s\n",
      "         2           0.6501           0.0060           22.78s\n",
      "         3           0.6558           0.0059           22.76s\n",
      "         4           0.6378           0.0056           23.09s\n",
      "         5           0.6309           0.0053           23.55s\n",
      "         6           0.6195           0.0061           23.44s\n",
      "         7           0.6129           0.0049           23.22s\n",
      "         8           0.6378           0.0049           23.27s\n",
      "         9           0.5766           0.0056           23.10s\n",
      "        10           0.5838           0.0048           23.23s\n",
      "        20           0.5310           0.0034           22.37s\n",
      "        30           0.4844           0.0024           21.78s\n",
      "        40           0.4498           0.0017           21.04s\n",
      "        50           0.4202           0.0015           20.30s\n",
      "        60           0.4120           0.0008           19.68s\n",
      "        70           0.3869           0.0006           19.07s\n",
      "        80           0.3669           0.0002           18.42s\n",
      "        90           0.3451           0.0002           17.80s\n",
      "       100           0.3461           0.0001           17.30s\n",
      "       200           0.2608          -0.0000           11.91s\n",
      "       300           0.2261          -0.0000            7.58s\n",
      "       400           0.1963          -0.0000            3.68s\n",
      "       500           0.1654          -0.0001            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6746           0.0063           22.40s\n",
      "         2           0.6561           0.0066           22.27s\n",
      "         3           0.6428           0.0062           22.58s\n",
      "         4           0.6432           0.0066           22.83s\n",
      "         5           0.6431           0.0055           23.53s\n",
      "         6           0.6402           0.0058           23.27s\n",
      "         7           0.6154           0.0047           23.25s\n",
      "         8           0.6045           0.0054           23.04s\n",
      "         9           0.6017           0.0051           22.83s\n",
      "        10           0.5969           0.0046           23.19s\n",
      "        20           0.5390           0.0035           22.67s\n",
      "        30           0.4844           0.0025           21.76s\n",
      "        40           0.4585           0.0015           21.05s\n",
      "        50           0.4216           0.0009           20.26s\n",
      "        60           0.3892           0.0010           19.60s\n",
      "        70           0.3940           0.0005           18.96s\n",
      "        80           0.3690           0.0004           18.44s\n",
      "        90           0.3622           0.0001           18.10s\n",
      "       100           0.3435           0.0003           17.74s\n",
      "       200           0.2765          -0.0000           12.73s\n",
      "       300           0.2327          -0.0001            8.07s\n",
      "       400           0.1953          -0.0001            3.95s\n",
      "       500           0.1750          -0.0000            0.00s\n",
      "CV score: 0.45302803\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_263 = np.zeros(train_shape)\n",
    "predictions_gbr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_263 = gbr(n_estimators=400, learning_rate=0.01,subsample=0.65,max_depth=7, min_samples_leaf=20,\n",
    "            max_features=0.22,verbose=1)\n",
    "    gbr_263.fit(tr_x,tr_y)\n",
    "    oof_gbr_263[val_idx] = gbr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_gbr_263 += gbr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.48597395\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_etr_263 = np.zeros(train_shape)\n",
    "predictions_etr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    etr_263 = etr(n_estimators=1000,max_depth=8, min_samples_leaf=12, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.4,verbose=1,n_jobs=-1)\n",
    "    etr_263.fit(tr_x,tr_y)\n",
    "    oof_etr_263[val_idx] = etr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_etr_263 += etr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_etr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4480463968181281"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack2 = np.vstack([oof_lgb_263,oof_xgb_263,oof_gbr_263,oof_rfr_263,oof_etr_263]).transpose()\n",
    "test_stack2 = np.vstack([predictions_lgb_263, predictions_xgb_263,predictions_gbr_263,predictions_rfr_263,predictions_etr_263]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack2 = np.zeros(train_stack2.shape[0])\n",
    "predictions_lr2 = np.zeros(test_stack2.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack2,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack2[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack2[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr2 = kr()\n",
    "    lr2.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack2[val_idx] = lr2.predict(val_data)\n",
    "    predictions_lr2 += lr2.predict(test_stack2) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's l2: 0.469917\tvalid_1's l2: 0.500224\n",
      "[2000]\ttraining's l2: 0.429395\tvalid_1's l2: 0.481374\n",
      "[3000]\ttraining's l2: 0.406698\tvalid_1's l2: 0.477093\n",
      "[4000]\ttraining's l2: 0.3889\tvalid_1's l2: 0.47561\n",
      "[5000]\ttraining's l2: 0.37349\tvalid_1's l2: 0.474608\n",
      "[6000]\ttraining's l2: 0.359817\tvalid_1's l2: 0.474433\n",
      "[7000]\ttraining's l2: 0.347254\tvalid_1's l2: 0.474529\n",
      "Early stopping, best iteration is:\n",
      "[6424]\ttraining's l2: 0.35435\tvalid_1's l2: 0.474245\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's l2: 0.469704\tvalid_1's l2: 0.497032\n",
      "[2000]\ttraining's l2: 0.428488\tvalid_1's l2: 0.479522\n",
      "[3000]\ttraining's l2: 0.405835\tvalid_1's l2: 0.476507\n",
      "[4000]\ttraining's l2: 0.388049\tvalid_1's l2: 0.475179\n",
      "[5000]\ttraining's l2: 0.372573\tvalid_1's l2: 0.474548\n",
      "[6000]\ttraining's l2: 0.358813\tvalid_1's l2: 0.474523\n",
      "Early stopping, best iteration is:\n",
      "[5486]\ttraining's l2: 0.365728\tvalid_1's l2: 0.474393\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's l2: 0.473478\tvalid_1's l2: 0.48336\n",
      "[2000]\ttraining's l2: 0.433025\tvalid_1's l2: 0.462168\n",
      "[3000]\ttraining's l2: 0.410423\tvalid_1's l2: 0.457888\n",
      "[4000]\ttraining's l2: 0.392744\tvalid_1's l2: 0.45658\n",
      "[5000]\ttraining's l2: 0.377506\tvalid_1's l2: 0.455625\n",
      "[6000]\ttraining's l2: 0.363929\tvalid_1's l2: 0.455815\n",
      "Early stopping, best iteration is:\n",
      "[5449]\ttraining's l2: 0.371265\tvalid_1's l2: 0.455441\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's l2: 0.471864\tvalid_1's l2: 0.497407\n",
      "[2000]\ttraining's l2: 0.431796\tvalid_1's l2: 0.4732\n",
      "[3000]\ttraining's l2: 0.40929\tvalid_1's l2: 0.466667\n",
      "[4000]\ttraining's l2: 0.391484\tvalid_1's l2: 0.464436\n",
      "[5000]\ttraining's l2: 0.376154\tvalid_1's l2: 0.463735\n",
      "[6000]\ttraining's l2: 0.362149\tvalid_1's l2: 0.463384\n",
      "[7000]\ttraining's l2: 0.349415\tvalid_1's l2: 0.463162\n",
      "Early stopping, best iteration is:\n",
      "[6660]\ttraining's l2: 0.353602\tvalid_1's l2: 0.463063\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's l2: 0.466527\tvalid_1's l2: 0.508134\n",
      "[2000]\ttraining's l2: 0.42591\tvalid_1's l2: 0.492228\n",
      "[3000]\ttraining's l2: 0.403997\tvalid_1's l2: 0.488581\n",
      "[4000]\ttraining's l2: 0.386593\tvalid_1's l2: 0.48624\n",
      "[5000]\ttraining's l2: 0.371575\tvalid_1's l2: 0.484432\n",
      "[6000]\ttraining's l2: 0.358121\tvalid_1's l2: 0.483887\n",
      "[7000]\ttraining's l2: 0.345707\tvalid_1's l2: 0.483582\n",
      "[8000]\ttraining's l2: 0.334321\tvalid_1's l2: 0.483367\n",
      "[9000]\ttraining's l2: 0.323729\tvalid_1's l2: 0.483199\n",
      "[10000]\ttraining's l2: 0.31373\tvalid_1's l2: 0.483463\n",
      "Early stopping, best iteration is:\n",
      "[9250]\ttraining's l2: 0.321153\tvalid_1's l2: 0.483071\n",
      "CV score: 0.47003963\n"
     ]
    }
   ],
   "source": [
    "##### lgb_49\n",
    "lgb_49_param = {\n",
    "'num_leaves': 9,\n",
    "'min_data_in_leaf': 23,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.002,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.45,\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.65,\n",
    "\"bagging_seed\": 15,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)   \n",
    "oof_lgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_lgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 12000\n",
    "    lgb_49 = lgb.train(lgb_49_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "    oof_lgb_49[val_idx] = lgb_49.predict(X_train_49[val_idx], num_iteration=lgb_49.best_iteration)\n",
    "    predictions_lgb_49 += lgb_49.predict(X_test_49, num_iteration=lgb_49.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:3.40422\tvalid_data-rmse:3.38325\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.527937\tvalid_data-rmse:0.718854\n",
      "[1000]\ttrain-rmse:0.435462\tvalid_data-rmse:0.720046\n",
      "Stopping. Best iteration:\n",
      "[529]\ttrain-rmse:0.521913\tvalid_data-rmse:0.718483\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:3.39826\tvalid_data-rmse:3.40774\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.528483\tvalid_data-rmse:0.70254\n",
      "[1000]\ttrain-rmse:0.438964\tvalid_data-rmse:0.703679\n",
      "Stopping. Best iteration:\n",
      "[600]\ttrain-rmse:0.509122\tvalid_data-rmse:0.701535\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:3.40192\tvalid_data-rmse:3.39291\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.532304\tvalid_data-rmse:0.665525\n",
      "[1000]\ttrain-rmse:0.438832\tvalid_data-rmse:0.667487\n",
      "Stopping. Best iteration:\n",
      "[458]\ttrain-rmse:0.541279\tvalid_data-rmse:0.664886\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:3.40243\tvalid_data-rmse:3.39011\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.533057\tvalid_data-rmse:0.679712\n",
      "[1000]\ttrain-rmse:0.44225\tvalid_data-rmse:0.681651\n",
      "Stopping. Best iteration:\n",
      "[480]\ttrain-rmse:0.537049\tvalid_data-rmse:0.67956\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:3.39341\tvalid_data-rmse:3.42628\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.535486\tvalid_data-rmse:0.661538\n",
      "[1000]\ttrain-rmse:0.441663\tvalid_data-rmse:0.665025\n",
      "Stopping. Best iteration:\n",
      "[514]\ttrain-rmse:0.53273\tvalid_data-rmse:0.661104\n",
      "\n",
      "CV score: 0.46986569\n"
     ]
    }
   ],
   "source": [
    "##### xgb_49\n",
    "xgb_49_params = {'eta': 0.02, \n",
    "              'max_depth': 5, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.35, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_xgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_49 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_49_params)\n",
    "    oof_xgb_49[val_idx] = xgb_49.predict(xgb.DMatrix(X_train_49[val_idx]), ntree_limit=xgb_49.best_ntree_limit)\n",
    "    predictions_xgb_49 += xgb_49.predict(xgb.DMatrix(X_test_49), ntree_limit=xgb_49.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6678           0.0034            8.77s\n",
      "         2           0.6444           0.0031           11.10s\n",
      "         3           0.6644           0.0030           10.49s\n",
      "         4           0.6452           0.0032            9.90s\n",
      "         5           0.6422           0.0032            9.53s\n",
      "         6           0.6596           0.0029            9.19s\n",
      "         7           0.6444           0.0029            8.93s\n",
      "         8           0.6397           0.0031            8.81s\n",
      "         9           0.6441           0.0027            8.78s\n",
      "        10           0.6207           0.0028            8.70s\n",
      "        20           0.5861           0.0026            8.48s\n",
      "        30           0.5525           0.0020            8.27s\n",
      "        40           0.5583           0.0016            8.15s\n",
      "        50           0.5307           0.0013            7.94s\n",
      "        60           0.5366           0.0009            7.91s\n",
      "        70           0.4961           0.0009            7.71s\n",
      "        80           0.4845           0.0007            7.70s\n",
      "        90           0.4825           0.0006            7.45s\n",
      "       100           0.4674           0.0005            7.25s\n",
      "       200           0.3960          -0.0000            5.34s\n",
      "       300           0.3761          -0.0001            3.76s\n",
      "       400           0.3469          -0.0000            2.38s\n",
      "       500           0.3320          -0.0000            1.16s\n",
      "       600           0.3145          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6401           0.0033            9.37s\n",
      "         2           0.6698           0.0035            9.05s\n",
      "         3           0.6682           0.0030            8.93s\n",
      "         4           0.6531           0.0033            8.73s\n",
      "         5           0.6496           0.0033            8.94s\n",
      "         6           0.6250           0.0033            9.08s\n",
      "         7           0.6374           0.0028            9.51s\n",
      "         8           0.6545           0.0028            9.54s\n",
      "         9           0.6512           0.0029            9.49s\n",
      "        10           0.6207           0.0026            9.45s\n",
      "        20           0.5974           0.0026            9.48s\n",
      "        30           0.5827           0.0020            9.09s\n",
      "        40           0.5598           0.0017            8.61s\n",
      "        50           0.5266           0.0013            8.23s\n",
      "        60           0.4985           0.0013            7.96s\n",
      "        70           0.5005           0.0009            7.71s\n",
      "        80           0.5048           0.0007            7.48s\n",
      "        90           0.4739           0.0006            7.27s\n",
      "       100           0.4568           0.0005            7.07s\n",
      "       200           0.3973           0.0001            5.31s\n",
      "       300           0.3683           0.0000            3.79s\n",
      "       400           0.3507          -0.0000            2.42s\n",
      "       500           0.3351          -0.0001            1.16s\n",
      "       600           0.3113          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6601           0.0036            8.22s\n",
      "         2           0.6581           0.0035            7.90s\n",
      "         3           0.6575           0.0034            7.96s\n",
      "         4           0.6588           0.0033            7.85s\n",
      "         5           0.6527           0.0031            7.91s\n",
      "         6           0.6397           0.0030            7.83s\n",
      "         7           0.6377           0.0030            8.02s\n",
      "         8           0.6285           0.0028            8.02s\n",
      "         9           0.6425           0.0030            8.01s\n",
      "        10           0.6224           0.0028            8.00s\n",
      "        20           0.5998           0.0021            7.84s\n",
      "        30           0.5538           0.0021            7.70s\n",
      "        40           0.5509           0.0016            7.47s\n",
      "        50           0.5282           0.0013            7.32s\n",
      "        60           0.5125           0.0012            7.14s\n",
      "        70           0.4856           0.0009            6.98s\n",
      "        80           0.4747           0.0008            6.86s\n",
      "        90           0.4605           0.0006            6.76s\n",
      "       100           0.4560           0.0005            6.56s\n",
      "       200           0.3793          -0.0000            5.10s\n",
      "       300           0.3561           0.0000            3.67s\n",
      "       400           0.3322          -0.0001            2.39s\n",
      "       500           0.3245          -0.0001            1.17s\n",
      "       600           0.3187          -0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6694           0.0029            7.60s\n",
      "         2           0.6642           0.0030            8.17s\n",
      "         3           0.6519           0.0032            8.16s\n",
      "         4           0.6646           0.0029            8.14s\n",
      "         5           0.6505           0.0033            8.25s\n",
      "         6           0.6684           0.0027            8.21s\n",
      "         7           0.6311           0.0033            8.44s\n",
      "         8           0.6387           0.0029            8.38s\n",
      "         9           0.6279           0.0027            8.46s\n",
      "        10           0.6230           0.0030            8.41s\n",
      "        20           0.6097           0.0020            8.07s\n",
      "        30           0.5893           0.0018            7.86s\n",
      "        40           0.5526           0.0014            7.57s\n",
      "        50           0.5205           0.0014            7.38s\n",
      "        60           0.5128           0.0010            7.20s\n",
      "        70           0.5149           0.0008            7.06s\n",
      "        80           0.4758           0.0008            7.16s\n",
      "        90           0.4783           0.0005            7.13s\n",
      "       100           0.4699           0.0006            6.96s\n",
      "       200           0.3994           0.0000            5.26s\n",
      "       300           0.3641           0.0001            3.80s\n",
      "       400           0.3450          -0.0001            2.46s\n",
      "       500           0.3322          -0.0001            1.21s\n",
      "       600           0.3159          -0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6580           0.0033            8.20s\n",
      "         2           0.6650           0.0033            8.18s\n",
      "         3           0.6603           0.0032            8.16s\n",
      "         4           0.6663           0.0031            8.15s\n",
      "         5           0.6501           0.0034            8.25s\n",
      "         6           0.6578           0.0029            8.31s\n",
      "         7           0.6565           0.0028            8.35s\n",
      "         8           0.6206           0.0033            8.38s\n",
      "         9           0.6287           0.0028            8.33s\n",
      "        10           0.6428           0.0031            8.29s\n",
      "        20           0.6002           0.0024            7.95s\n",
      "        30           0.5732           0.0021            7.90s\n",
      "        40           0.5477           0.0018            7.72s\n",
      "        50           0.5276           0.0013            7.47s\n",
      "        60           0.5199           0.0014            7.39s\n",
      "        70           0.4979           0.0010            7.20s\n",
      "        80           0.4797           0.0008            7.04s\n",
      "        90           0.4820           0.0006            6.83s\n",
      "       100           0.4533           0.0005            6.68s\n",
      "       200           0.4014           0.0001            5.16s\n",
      "       300           0.3576           0.0000            3.68s\n",
      "       400           0.3448          -0.0001            2.36s\n",
      "       500           0.3301          -0.0000            1.14s\n",
      "       600           0.3002          -0.0000            0.00s\n",
      "CV score: 0.46735521\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_49 = np.zeros(train_shape)\n",
    "predictions_gbr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_49 = gbr(n_estimators=600, learning_rate=0.01,subsample=0.65,max_depth=6, min_samples_leaf=20,\n",
    "            max_features=0.35,verbose=1)\n",
    "    gbr_49.fit(tr_x,tr_y)\n",
    "    oof_gbr_49[val_idx] = gbr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_gbr_49 += gbr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46612748508142104"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack3 = np.vstack([oof_lgb_49,oof_xgb_49,oof_gbr_49]).transpose()\n",
    "test_stack3 = np.vstack([predictions_lgb_49, predictions_xgb_49,predictions_gbr_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack3 = np.zeros(train_stack3.shape[0])\n",
    "predictions_lr3 = np.zeros(test_stack3.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack3,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack3[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack3[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr3 = kr()\n",
    "    lr3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack3[val_idx] = lr3.predict(val_data)\n",
    "    predictions_lr3 += lr3.predict(test_stack3) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.51672379\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_383 = np.zeros(train_shape)\n",
    "predictions_kr_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_383 = kr()\n",
    "    kr_383.fit(tr_x,tr_y)\n",
    "    oof_kr_383[val_idx] = kr_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_kr_383 += kr_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48663633\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_383 = np.zeros(train_shape)\n",
    "predictions_ridge_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_383 = Ridge(alpha=1200)\n",
    "    ridge_383.fit(tr_x,tr_y)\n",
    "    oof_ridge_383[val_idx] = ridge_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_ridge_383 += ridge_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53292758\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_383 = np.zeros(train_shape)\n",
    "predictions_en_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_383 = en(alpha=1.0,l1_ratio=0.06)\n",
    "    en_383.fit(tr_x,tr_y)\n",
    "    oof_en_383[val_idx] = en_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_en_383 += en_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48690239\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_383 = np.zeros(train_shape)\n",
    "predictions_br_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_383 = br()\n",
    "    br_383.fit(tr_x,tr_y)\n",
    "    oof_br_383[val_idx] = br_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_br_383 += br_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48741703582621976"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack1 = np.vstack([oof_br_383,oof_kr_383,oof_en_383,oof_ridge_383]).transpose()\n",
    "test_stack1 = np.vstack([predictions_br_383, predictions_kr_383,predictions_en_383,predictions_ridge_383]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack1 = np.zeros(train_stack1.shape[0])\n",
    "predictions_lr1 = np.zeros(test_stack1.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack1,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack1[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack1[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr1 = lr()\n",
    "    lr1.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack1[val_idx] = lr1.predict(val_data)\n",
    "    predictions_lr1 += lr1.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.50253564\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_49 = np.zeros(train_shape)\n",
    "predictions_kr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_49 = kr()\n",
    "    kr_49.fit(tr_x,tr_y)\n",
    "    oof_kr_49[val_idx] = kr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_kr_49 += kr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49448122\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_49 = np.zeros(train_shape)\n",
    "predictions_ridge_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_49 = Ridge(alpha=6)\n",
    "    ridge_49.fit(tr_x,tr_y)\n",
    "    oof_ridge_49[val_idx] = ridge_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_ridge_49 += ridge_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49531741\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_49 = np.zeros(train_shape)\n",
    "predictions_br_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_49 = br()\n",
    "    br_49.fit(tr_x,tr_y)\n",
    "    oof_br_49[val_idx] = br_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_br_49 += br_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53837394\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_49 = np.zeros(train_shape)\n",
    "predictions_en_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_49 = en(alpha=1.0,l1_ratio=0.05)\n",
    "    en_49.fit(tr_x,tr_y)\n",
    "    oof_en_49[val_idx] = en_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_en_49 += en_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4948833548008857"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack4 = np.vstack([oof_br_49,oof_kr_49,oof_en_49,oof_ridge_49]).transpose()\n",
    "test_stack4 = np.vstack([predictions_br_49, predictions_kr_49,predictions_en_49,predictions_ridge_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack4 = np.zeros(train_stack4.shape[0])\n",
    "predictions_lr4 = np.zeros(test_stack4.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack4,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack4[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack4[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr4 = lr()\n",
    "    lr4.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack4[val_idx] = lr4.predict(val_data)\n",
    "    predictions_lr4 += lr4.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45237728799822047"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(target.values, 0.7*(0.6*oof_stack2 + 0.4*oof_stack3)+0.3*(0.55*oof_stack1+0.45*oof_stack4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44761953946346983"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack5 = np.vstack([oof_stack1,oof_stack2,oof_stack3,oof_stack4]).transpose()\n",
    "test_stack5 = np.vstack([predictions_lr1, predictions_lr2,predictions_lr3,predictions_lr4]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack5 = np.zeros(train_stack5.shape[0])\n",
    "predictions_lr5= np.zeros(test_stack5.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack5,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack5[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack5[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr5 = lr()\n",
    "    lr5.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack5[val_idx] = lr5.predict(val_data)\n",
    "    predictions_lr5 += lr5.predict(test_stack5) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.881401\n",
       "std         0.535058\n",
       "min         1.142868\n",
       "25%         3.669060\n",
       "50%         3.985149\n",
       "75%         4.215604\n",
       "max         5.311432\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example = pd.read_csv('d:/tianchi/happiness/happiness_submit.csv',sep=',',encoding='latin-1')\n",
    "\n",
    "submit_example['happiness'] = predictions_lr5\n",
    "\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.881187\n",
       "std         0.534565\n",
       "min         1.142868\n",
       "25%         3.669060\n",
       "50%         3.985149\n",
       "75%         4.215604\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example.loc[submit_example['happiness']>4.96,'happiness']= 5\n",
    "# submit_example.loc[submit_example['happiness']<=1.2,'happiness']= 1\n",
    "# submit_example.loc[(submit_example['happiness']>1.95)&(submit_example['happiness']<2.05),'happiness']= 2\n",
    "# submit_example.loc[(submit_example['happiness']>2.95)&(submit_example['happiness']<3.05),'happiness']= 3\n",
    "# submit_example.loc[(submit_example['happiness']>3.95)&(submit_example['happiness']<4.05),'happiness']= 4\n",
    "\n",
    "submit_example.to_csv(\"d:/tianchi/happiness/submision_stacking_4lr_post_v3.csv\",index=False)\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
